{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jatin2055/langchain-chains?scriptVersionId=260101199\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:07.785799Z","iopub.execute_input":"2025-09-05T08:23:07.786142Z","iopub.status.idle":"2025-09-05T08:23:07.793704Z","shell.execute_reply.started":"2025-09-05T08:23:07.786109Z","shell.execute_reply":"2025-09-05T08:23:07.792644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pip install langchain\n# pip install langchain_openai\n# pip install langchain_huggingface\n# pip install pydantic\n# pip install grandalf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:07.796606Z","iopub.execute_input":"2025-09-05T08:23:07.796872Z","iopub.status.idle":"2025-09-05T08:23:07.831548Z","shell.execute_reply.started":"2025-09-05T08:23:07.796853Z","shell.execute_reply":"2025-09-05T08:23:07.830591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:07.833202Z","iopub.execute_input":"2025-09-05T08:23:07.833579Z","iopub.status.idle":"2025-09-05T08:23:10.361669Z","shell.execute_reply.started":"2025-09-05T08:23:07.833549Z","shell.execute_reply":"2025-09-05T08:23:10.360314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"api_key='your_api_key'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:49:14.923014Z","iopub.execute_input":"2025-09-05T08:49:14.923893Z","iopub.status.idle":"2025-09-05T08:49:14.927962Z","shell.execute_reply.started":"2025-09-05T08:49:14.923861Z","shell.execute_reply":"2025-09-05T08:49:14.926949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ChatOpenAI(api_key=api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:49:16.526147Z","iopub.execute_input":"2025-09-05T08:49:16.526513Z","iopub.status.idle":"2025-09-05T08:49:16.532502Z","shell.execute_reply.started":"2025-09-05T08:49:16.526487Z","shell.execute_reply":"2025-09-05T08:49:16.531295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Creating Sequential chain","metadata":{}},{"cell_type":"code","source":"prompt = PromptTemplate(\n    template = 'Give me five latest movies/series from {genre}',\n    input = ['genre']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:11.033111Z","iopub.execute_input":"2025-09-05T08:23:11.033452Z","iopub.status.idle":"2025-09-05T08:23:11.039088Z","shell.execute_reply.started":"2025-09-05T08:23:11.033424Z","shell.execute_reply":"2025-09-05T08:23:11.037979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"str_parser = StrOutputParser()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:11.040222Z","iopub.execute_input":"2025-09-05T08:23:11.040545Z","iopub.status.idle":"2025-09-05T08:23:11.064756Z","shell.execute_reply.started":"2025-09-05T08:23:11.040522Z","shell.execute_reply":"2025-09-05T08:23:11.063501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample 1","metadata":{}},{"cell_type":"code","source":"simple_chain = prompt | model | str_parser\n\nresult = simple_chain.invoke({'genre': 'Manga'})\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:11.065815Z","iopub.execute_input":"2025-09-05T08:23:11.066066Z","iopub.status.idle":"2025-09-05T08:23:12.730545Z","shell.execute_reply.started":"2025-09-05T08:23:11.066047Z","shell.execute_reply":"2025-09-05T08:23:12.729309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing your chain","metadata":{}},{"cell_type":"code","source":"simple_chain.get_graph().print_ascii()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:12.732038Z","iopub.execute_input":"2025-09-05T08:23:12.732458Z","iopub.status.idle":"2025-09-05T08:23:12.804932Z","shell.execute_reply.started":"2025-09-05T08:23:12.732432Z","shell.execute_reply":"2025-09-05T08:23:12.804086Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample 2","metadata":{}},{"cell_type":"code","source":"prompt1 = PromptTemplate(\n    template = 'Give me {no_of_movies} latest movies/series from {genre} ',\n    input = ['no_of_movies', 'genre']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:12.807551Z","iopub.execute_input":"2025-09-05T08:23:12.808158Z","iopub.status.idle":"2025-09-05T08:23:12.814249Z","shell.execute_reply.started":"2025-09-05T08:23:12.808131Z","shell.execute_reply":"2025-09-05T08:23:12.813052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt2 = PromptTemplate(\n    template = 'Give me atleast one character from all the movie/series in {list_of_movies}. Also mention the name of movie/series along with the character.',\n    input = ['list_of_movies']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:12.815499Z","iopub.execute_input":"2025-09-05T08:23:12.815799Z","iopub.status.idle":"2025-09-05T08:23:12.844511Z","shell.execute_reply.started":"2025-09-05T08:23:12.815776Z","shell.execute_reply":"2025-09-05T08:23:12.843322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"str_parser = StrOutputParser()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:12.845252Z","iopub.execute_input":"2025-09-05T08:23:12.845722Z","iopub.status.idle":"2025-09-05T08:23:12.86833Z","shell.execute_reply.started":"2025-09-05T08:23:12.845689Z","shell.execute_reply":"2025-09-05T08:23:12.867145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_chain = prompt1 | model | str_parser | prompt2 | model | str_parser\n\nresult = seq_chain.invoke({\"no_of_movies\": 5, \"genre\": \"bollywood\"})\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:12.869287Z","iopub.execute_input":"2025-09-05T08:23:12.869609Z","iopub.status.idle":"2025-09-05T08:23:15.551837Z","shell.execute_reply.started":"2025-09-05T08:23:12.869586Z","shell.execute_reply":"2025-09-05T08:23:15.550693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_chain.get_graph().print_ascii()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.553479Z","iopub.execute_input":"2025-09-05T08:23:15.553802Z","iopub.status.idle":"2025-09-05T08:23:15.56453Z","shell.execute_reply.started":"2025-09-05T08:23:15.553778Z","shell.execute_reply":"2025-09-05T08:23:15.563002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Parallel Chain","metadata":{}},{"cell_type":"code","source":"from langchain.schema.runnable import RunnableParallel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.56574Z","iopub.execute_input":"2025-09-05T08:23:15.566103Z","iopub.status.idle":"2025-09-05T08:23:15.623451Z","shell.execute_reply.started":"2025-09-05T08:23:15.566038Z","shell.execute_reply":"2025-09-05T08:23:15.621982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt1 = PromptTemplate(\n    template = 'Generate short and simple notes from the following text: {text}',\n    input = ['text']\n)\n\nprompt2 = PromptTemplate(\n    template = 'Generate short quiz from the following text: {text}',\n    input_variables = ['text']\n)\n\nprompt3 = PromptTemplate(\n    template = 'Merge both notes and quiz into a single doc note: {notes} , quiz: {quiz}',\n    input_variables = ['notes', 'quiz']\n)\n\nstr_parser = StrOutputParser()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.62455Z","iopub.execute_input":"2025-09-05T08:23:15.624846Z","iopub.status.idle":"2025-09-05T08:23:15.631277Z","shell.execute_reply.started":"2025-09-05T08:23:15.624823Z","shell.execute_reply":"2025-09-05T08:23:15.630307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_text = \"\"\" SLMs’ Aptitude for Agentic Tasks\nSeveral arguments are provided to support this view. One is based on empirical evidence that SLM performance is rapidly improving, with models like Phi-2, Phi-3, SmoILM2, and more, reporting promising results. On another note, as AI agents are typically instructed to excel at a limited range of language model capabilities, properly fine-tuned SLMs should often be appropriate for most domain-specific applications, with the added benefits of efficiency and flexibility.\n\nSLMs’ Suitability for Agentic AI Architectures\nThe small size and reduced pre-training and fine-tuning costs of SLMs make them easier to accommodate in typically modular agentic AI architectures and easier to adapt to ever-evolving user needs, behaviors, and requirements. Meanwhile, a well-fine-tuned SLM for selected domain-specific prompt sets can be sufficient for specialized systems and settings, although LLMs will generally have a broader understanding of language and the world as a whole. On another note, as AI agents frequently interact with code, conformance to certain formatting requirements is also a concern to ensure consistency. Consequently, SLMs trained with narrower formatting specifications would be preferable.\n\nThe heterogeneity inherent in agentic systems and interactions is another reason why SLMs are argued to be more suitable for agentic architectures, as these interactions serve as a pathway to gather data.\n\nSLMs’ Economic Feasibility\nSLM flexibility can be easily translated into a higher potential for democratization. The aforementioned reduced operational costs are a major reason for this. In more economic terms, the paper compares SLMs against LLMs concerning inference efficiency, fine-tuning agility, edge deployment, and parameter usage: aspects in which SLMs are considered superior.\n\nAlternative Views, Barriers, and Discussion\nThe authors not only present their view, but they also outline and address counterarguments solidly founded on existing literature. These include statements like LLMs generally outperforming SLMs due to scalability laws (which may not always hold for narrow subtasks or task-specific fine-tuning), centralized LLM infrastructure being cheaper at scale (which can be countered by decreasing costs and modular SLM deployments that prevent bottlenecks), and industry inertia favoring LLMs over SLMs (which, while true, does not outweigh other SLM advantages like adaptability and economic efficiency, among others).\n\nThe main barrier to adopting SLMs as the universal go-to approach alongside agentic systems is the well-established dominance of LLMs from many perspectives, not just technical ones, accompanied by substantial investments made in LLM-centric pipelines. Clearly demonstrating the discussed advantages of SLMs is paramount to motivating and facilitating a transition from LLMs to SLMs in agentic solutions.\n\nTo finalize this analysis and summary of the paper, here are some of my own perspectives on what we have outlined and discussed. Specifically, while the claims made throughout the paper are brilliantly well-founded and convincing, in our rapidly changing world, paradigm shifts are often subject to barriers. Accordingly, I consider the following to be three major barriers to adopting SLMs as the main approach underlying agentic AI systems:\n\nThe huge investments made in LLM infrastructure (already highlighted by the authors) make it difficult to change the status quo, at least in the short term, due to the strong economic inertia behind LLM-centric pipelines.\nWe may have to rethink evaluation benchmarks to adapt them for SLM-based frameworks, as current benchmarks are designed to prioritize general performance aspects rather than narrow, specialized performance in agentic systems.\nLast, and perhaps simplest, there is still work to be done in terms of raising public awareness about the potential and advances made by SLMs. The “LLM” buzzword is deeply rooted in society, and the LLM-first mindset will take time and effort to evolve before decision-makers and practitioners jointly view SLMs as a possible replacement with its own advantages, especially regarding their integration into real-world agentic AI solutions.\nOn a final, personal note, if major cloud infrastructure providers were to embrace and more aggressively promote the authors’ view on the potential of SLMs to lead agentic AI development, perhaps a significant portion of this journey could be covered in the blink of an eye.\n\n \"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.632523Z","iopub.execute_input":"2025-09-05T08:23:15.632863Z","iopub.status.idle":"2025-09-05T08:23:15.656697Z","shell.execute_reply.started":"2025-09-05T08:23:15.632833Z","shell.execute_reply":"2025-09-05T08:23:15.655431Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample","metadata":{}},{"cell_type":"code","source":"parallel_chain = RunnableParallel({\n    'notes':  prompt1 | model | str_parser,\n    'quiz': prompt2 | model | str_parser\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.657909Z","iopub.execute_input":"2025-09-05T08:23:15.658171Z","iopub.status.idle":"2025-09-05T08:23:15.685948Z","shell.execute_reply.started":"2025-09-05T08:23:15.658144Z","shell.execute_reply":"2025-09-05T08:23:15.684825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_chain = prompt3 | model | str_parser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.687105Z","iopub.execute_input":"2025-09-05T08:23:15.687733Z","iopub.status.idle":"2025-09-05T08:23:15.834769Z","shell.execute_reply.started":"2025-09-05T08:23:15.687702Z","shell.execute_reply":"2025-09-05T08:23:15.83384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_chain = parallel_chain | merged_chain\n\nresult = final_chain.invoke({'text': input_text})\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:15.836016Z","iopub.execute_input":"2025-09-05T08:23:15.836386Z","iopub.status.idle":"2025-09-05T08:23:19.1372Z","shell.execute_reply.started":"2025-09-05T08:23:15.836333Z","shell.execute_reply":"2025-09-05T08:23:19.136366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"final_chain.get_graph().print_ascii()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:23:19.138126Z","iopub.execute_input":"2025-09-05T08:23:19.138394Z","iopub.status.idle":"2025-09-05T08:23:19.152119Z","shell.execute_reply.started":"2025-09-05T08:23:19.138363Z","shell.execute_reply":"2025-09-05T08:23:19.151169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Conditional Chains","metadata":{}},{"cell_type":"code","source":"from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom typing import Literal\nfrom pydantic import BaseModel, Field\nfrom langchain.schema.runnable import RunnableBranch, RunnableLambda\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:48:09.393374Z","iopub.execute_input":"2025-09-05T08:48:09.393763Z","iopub.status.idle":"2025-09-05T08:48:09.403108Z","shell.execute_reply.started":"2025-09-05T08:48:09.393736Z","shell.execute_reply":"2025-09-05T08:48:09.40062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hug_api_key = 'your_api_key' ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:31:49.189123Z","iopub.execute_input":"2025-09-05T08:31:49.189509Z","iopub.status.idle":"2025-09-05T08:31:49.194931Z","shell.execute_reply.started":"2025-09-05T08:31:49.189474Z","shell.execute_reply":"2025-09-05T08:31:49.193734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm = HuggingFaceEndpoint(\n    repo_id = \"google/gemma-2-2b-it\",\n    task=\"text-generation\",\n    huggingfacehub_api_token = hug_api_key\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:31:50.590659Z","iopub.execute_input":"2025-09-05T08:31:50.591127Z","iopub.status.idle":"2025-09-05T08:31:50.600703Z","shell.execute_reply.started":"2025-09-05T08:31:50.59109Z","shell.execute_reply":"2025-09-05T08:31:50.599414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hugging_face_model = ChatHuggingFace(llm=llm )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:31:52.404507Z","iopub.execute_input":"2025-09-05T08:31:52.40483Z","iopub.status.idle":"2025-09-05T08:31:52.411932Z","shell.execute_reply.started":"2025-09-05T08:31:52.404803Z","shell.execute_reply":"2025-09-05T08:31:52.410913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"str_parser = StrOutputParser()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:48:12.273243Z","iopub.execute_input":"2025-09-05T08:48:12.276261Z","iopub.status.idle":"2025-09-05T08:48:12.283888Z","shell.execute_reply.started":"2025-09-05T08:48:12.276188Z","shell.execute_reply":"2025-09-05T08:48:12.281464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Feedback(BaseModel):\n    sentiment: Literal[\"positive\", \"negative\"] = Field(description=\"Provide sentiment of the provided feedback\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:48:14.135766Z","iopub.execute_input":"2025-09-05T08:48:14.136141Z","iopub.status.idle":"2025-09-05T08:48:14.144987Z","shell.execute_reply.started":"2025-09-05T08:48:14.136112Z","shell.execute_reply":"2025-09-05T08:48:14.142982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pyd_parser = PydanticOutputParser(pydantic_object = Feedback)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:48:18.672206Z","iopub.execute_input":"2025-09-05T08:48:18.673476Z","iopub.status.idle":"2025-09-05T08:48:18.683024Z","shell.execute_reply.started":"2025-09-05T08:48:18.673405Z","shell.execute_reply":"2025-09-05T08:48:18.680325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt1 = PromptTemplate(\n    template = \"Classify the sentiment into positive or negative based on the feedback: {feedback}. \\n\\n {format_instructions}\",\n    input_variables = [\"feedback\"],\n    partial_variables = {\"format_instructions\": pyd_parser.get_format_instructions()}\n)\n\n\nprompt2 = PromptTemplate(\n    template = 'Write an appropriate response to this positive feedback: {feedback}',\n    input_variables = ['feedback']\n)\n\nprompt3 = PromptTemplate(\n    template = 'Write an appropriate response to this negative feedback: {feedback}',\n    input_variables = ['feedback']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:48:20.015019Z","iopub.execute_input":"2025-09-05T08:48:20.01575Z","iopub.status.idle":"2025-09-05T08:48:20.028476Z","shell.execute_reply.started":"2025-09-05T08:48:20.015713Z","shell.execute_reply":"2025-09-05T08:48:20.026312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classifier_chain = prompt1 | hugging_face_model | pyd_parser\n\n#print(classifier_chain.invoke({\"feedback\": feedback}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:53:41.922045Z","iopub.execute_input":"2025-09-05T08:53:41.922449Z","iopub.status.idle":"2025-09-05T08:53:41.926641Z","shell.execute_reply.started":"2025-09-05T08:53:41.922414Z","shell.execute_reply":"2025-09-05T08:53:41.925735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample","metadata":{}},{"cell_type":"code","source":"branch_chain = RunnableBranch(\n    (lambda x: x.sentiment == 'positive', prompt2 | hugging_face_model | str_parser ),\n    (lambda x: x.sentiment == 'negative', prompt3 | hugging_face_model | str_parser),\n    RunnableLambda(lambda x:  \"Not sentiment found\") # default chain\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:53:44.514384Z","iopub.execute_input":"2025-09-05T08:53:44.514724Z","iopub.status.idle":"2025-09-05T08:53:44.520081Z","shell.execute_reply.started":"2025-09-05T08:53:44.514695Z","shell.execute_reply":"2025-09-05T08:53:44.519055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feedback = 'The phone has an excellent display with vibrant colors and smooth refresh rate. Battery life comfortably lasts through a full day of heavy use, and the camera captures sharp, detailed pictures even in low light. The overall performance feels snappy, making multitasking effortless'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:55:38.615651Z","iopub.execute_input":"2025-09-05T08:55:38.615968Z","iopub.status.idle":"2025-09-05T08:55:38.620979Z","shell.execute_reply.started":"2025-09-05T08:55:38.615945Z","shell.execute_reply":"2025-09-05T08:55:38.620103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conditional_chain = classifier_chain | branch_chain\n\nresult = conditional_chain.invoke({\"feedback\": feedback})\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:55:43.313197Z","iopub.execute_input":"2025-09-05T08:55:43.314472Z","iopub.status.idle":"2025-09-05T08:55:50.215584Z","shell.execute_reply.started":"2025-09-05T08:55:43.314427Z","shell.execute_reply":"2025-09-05T08:55:50.214486Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Vizualization","metadata":{}},{"cell_type":"code","source":"conditional_chain.get_graph().print_ascii()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T08:56:52.613404Z","iopub.execute_input":"2025-09-05T08:56:52.61371Z","iopub.status.idle":"2025-09-05T08:56:52.634763Z","shell.execute_reply.started":"2025-09-05T08:56:52.613686Z","shell.execute_reply":"2025-09-05T08:56:52.633596Z"}},"outputs":[],"execution_count":null}]}