{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T08:18:05.749018Z","iopub.execute_input":"2025-09-12T08:18:05.749454Z","iopub.status.idle":"2025-09-12T08:18:06.122639Z","shell.execute_reply.started":"2025-09-12T08:18:05.749425Z","shell.execute_reply":"2025-09-12T08:18:06.121257Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# pip install langchain langchain-openai langchain-community langchain-core youtube-transcript-api faiss_cpu ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\nfrom youtube_transcript_api.proxies import WebshareProxyConfig\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_community.document_loaders import YoutubeLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:43:14.937939Z","iopub.execute_input":"2025-09-12T10:43:14.938290Z","iopub.status.idle":"2025-09-12T10:43:24.798055Z","shell.execute_reply.started":"2025-09-12T10:43:14.938267Z","shell.execute_reply":"2025-09-12T10:43:24.797184Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# 1. Indexing\n\n# 1.1 Document Ingestion","metadata":{}},{"cell_type":"code","source":"try:\n    # using webshare proxy to fetch youtube transcripts\n\n\n    video_id = 'nlz9j-r0U9U'\n    \n    ytt_api = YouTubeTranscriptApi(\n        proxy_config=WebshareProxyConfig(\n            proxy_username=\"\",\n            proxy_password=\"\",\n        )\n    )\n\n    \n    # all requests done by ytt_api will now be proxied through Webshare\n    ytt_transcripts = ytt_api.fetch(video_id, languages=['en']) # can also use 'hi' for hindi\n\n\nexcept TranscriptsDisabled:\n    print(\"Transcripts are disabled for this video.\")\nexcept Exception as e:\n    print(f\"Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:07:35.458367Z","iopub.execute_input":"2025-09-12T11:07:35.458682Z","iopub.status.idle":"2025-09-12T11:08:07.049163Z","shell.execute_reply.started":"2025-09-12T11:07:35.458663Z","shell.execute_reply":"2025-09-12T11:08:07.048029Z"}},"outputs":[{"name":"stdout","text":"Error: \nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=nlz9j-r0U9U! This is most likely caused by:\n\nNo transcripts were found for any of the requested language codes: ('en',)\n\nFor this video (nlz9j-r0U9U) transcripts are available in the following languages:\n\n(MANUALLY CREATED)\nNone\n\n(GENERATED)\n - hi (\"Hindi (auto-generated)\")\n\n(TRANSLATION LANGUAGES)\nNone\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# combined transcript\ncombined_transcript = \"\".join(res.text for res in ytt_transcripts)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:30:24.571304Z","iopub.execute_input":"2025-09-12T11:30:24.571641Z","iopub.status.idle":"2025-09-12T11:30:24.576146Z","shell.execute_reply.started":"2025-09-12T11:30:24.571615Z","shell.execute_reply":"2025-09-12T11:30:24.575181Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# workwound of youtube transcript\n\n# combined_transcript = \"\"\"If you're using Chhatubt, Claude,Gemini, Perplexity, or other AI toolsand you're getting responses that soundconfident but might be completely wrong,you're probably thinking, \"Well, I justneed to be more specific, or maybe Ineed better AI tools.\" That's exactlywhat I thought, too. But after testingthousands of prompts, I discoveredsomething that completely shatteredeverything I believed about AI. Theproblem is that most people are speakinga completely different language thanwhat AI actually understands. The skillof bridging that language gap is calledprompt engineering. So, in this video,I'll teach you how to speak AI's actuallanguage. Plus, I'll show you advancedhacks that make AI admit when it'sguessing, get AI to quality controlitself, and give you way more confidencein AI's output. All right, let me showyou what's actually going on behind thescenes when you get inconsistent AIresults. AI seems unpredictable, butthere's actually a method to themadness. Every response follows exactmathematical patterns based on what'scalled token probability. So when youtype write me an email, the AIcalculates the probability of whatshould come next. But most people aregiving it the wrong type of data. You'regiving it random words when AI needsstructured probability inputs. Withoutthe right type of data, the AI isspinning a roulette wheel betweenmillions of different email patterns.Business email, personal email, salesemail, breakup email. It's literallyguessing. But once you understand how tofeed it structured data inputs insteadof random details, everything changes.You guide it to the exact pattern thatyou want instead of letting it guess.And that's exactly what I'm about toshow you. Now that you understand how AIactually works, and before I show youthe crazy hacks that are going to blowyour mind, you need to understand thefoundation that makes everything elsework. The gold standard for promptingand what gets consistently amazingresults is using a six-part framework.This aligns with what Google teaches intheir 9-hour prompt engineering coursethat I completed. This isn't a secret.It's just that most people never learnthe structure. Let me walk you throughthis using a quick example. Let's sayyou have a fitness app and you'recrafting an email to reach out to yourcustomers. Number one is the role. Tellthe AI who it is. This sets thefoundation for how AI thinks andresponds. So, you tell the AI who itshould be. Instead of getting genericrobotic answers, this gives you aspecific voice and expertise. So in thisexample, we'd start with you are afitness app founder. Number two is thecontext. So set the situation and givethe AI some background. So for thisexample, we could say reaching out tousers who downloaded the app 2 weeks agobut haven't logged a single workout yet.So just explaining the background.Number three is the task. So beingspecific about what we actually wantedto do. So, for this example, we couldsay, \"Write an encouraging email thatmotivates them to try their first10-minute workout without making themfeel guilty.\" Number four is the format.So, we need to define the output. So, dowe want it in bullet point form? Do wewant a certain amount of word count? Weneed to specify how we want theinformation. So for this example, wecould say something like return as a100word email with an upbeat subjectline, empathetic opening, one specificaction step, and motivational closingtells exactly what we're looking for.Number five is rules. So set someboundaries or constraints. Is thereanything you don't want it to talkabout? Are there things that you do wantit to say specifically? This is theopportunity to do that. So for thisexample, we could say something like, dokeep it supportive and encouraging.Don't use guilt, shame, or pressuretactics. Tells it exactly what to avoid.And number six is examples. This is thesecret sauce and where most people missthe real power. You can show the AI whatgood looks like and you can do it in acouple of different ways. Depending onwhat you're actually looking for AI tohelp you with, you can give it textexamples or you can upload actualimages, emails, documents for the AI toanalyze and match. So, for our fitnessapp example, I could upload amotivational email and say somethinglike this. Match this energetic andsupportive tone that makes people feelcapable and referred to the uploadedimage. Now, let me show you thetransformation that this makes in realtime. Here's what a lot of people wouldtype. Write me a fitness marketing emailfor my fitness app. And here's what weget. Generic, templated, could be forany business. Now, let's put all sixparts together of the example that wejust went through just to compare. Youare a fitness app founder, reaching outto users who downloaded your app twoweeks ago but haven't logged a singleworkout. Write an encouraging email thatmotivates them to try their 10-minuteworkout without making them feel guilty.Return as a 100word email with an upbeatsubject line, empathetic opening, onespecific action step, motivationalclosing. Do keep it supportive andencouraging. Don't use guilt, shame, orpressure tactics. And match thisenergetic, supportive tone that makespeople feel capable. And refer to theuploaded image. Look at thattransformation. It sounds like it'swritten by a real person and speaks tothe exact issues that we're trying toaddress. This foundation makeseverything else I'm about to show youwork 10 times better. All right, let meshow you the six gamechanging hacks thatwill take this foundation and turn itinto something incredible. Hack numberone is the truth detector. This is thehack that prevents embarrassing AImistakes that could damage yourreputation or cost you money. Mostpeople don't realize that AI soundsconfident even when it's completelyguessing. So, I force it to rate its ownconfidence. I add this to everyimportant prompt. For each claim, rateyour confidence. Virtually certain, 95%and above. Highly confidence, 80 to 95%.Moderately confident, 60 to 80%,speculative, or low confidence, below40%. And explain your confidence level.Let me show you this in action. I'mgoing to ask it something it may not beentirely sure about. Let me use theframework we just learned. You are amarketing consultant with 10 years ofexperience in restaurant marketing.That's our role. Client is asking aboutstrategies to increase foot traffic andonline orders for their restaurant.That's the context. Provide fivestrategies with explanations. That's thetask. Return as a numbered list withbrief explanations for each strategy.That's the format we're looking for. Dofocus on proven methods and emergingtrends. Don't include outdated tactics.That's the rule. That's our constraint.And for each strategy, rate yourconfidence. This is where I'm going toput in what we just talked about.virtually certain, highly confident,etc. And let's see what it comes backwith. See how it's telling me it'svirtually certain about strategy numberone. Then it moves to highly confidentfor strategy number two, and then downto the last couple, four and five. It'sonly moderately confident in those ones.Now, the AI can tell me when it'sbasically guessing. This has saved mefrom so many embarrassing mistakes. Nomore blindly trusting AI when it's justmaking educated guesses. Now that youknow how to catch AI when it's makingthings up, what I'm about to show youwill completely change how you createprompts in the first place. Hack numbertwo is the AI prompt helper. This issuch a game changer. Another method thatI use when I'm struggling with promptsis I get AI to help me with theprompting itself. There's two awesomeways to do this. Approach number one isstarting from scratch. Instead of tryingto figure out the best way to ask forsomething with a prompt, if I waslooking to use AI to help plan a weekendtrip, I could simply say, \"I want toplan a perfect weekend getaway for twopeople on an $800 budget within drivingdistance of Chicago. Write the optimalprompt that I should use to get the besttravel recommendations from you.\" Lookat this. The AI just wrote me a nicelystructured prompt with context, specificinstructions, the output format, and itknows how it wants to be prompted. Andnow I'm going to use the prompt that itjust gave me. I'm going to copy andpaste that right into the prompt box.And here's what we get. Amazing, right?It's given us some really goodrecommendations in here with things todo, where to stay, the cost breakdown,how long the driving distances away fromChicago. Perfect. This is great. Now,here's approach number two, and thisone's for when you're frustrated withyour AI results. Let's say you alreadywrote a prompt, but you gotdisappointing results. Instead ofgetting frustrated and trying to guesswhat went wrong, I'm going to say, Itried this prompt. Plan a weekend tripfor me and my friend. We have about $800to spend and want to go somewhere withindriving distance. Give me some ideas.But the output wasn't great. Can youanalyze my original prompt and improveit to get a better result? And look whatit generated. It's identifying exactlywhat was missing. Too vague on location,no interest mentioned, no context ontravel dates, no preference on the vibe,and then it gives us an improved versionof the prompt where we can fill inadditional details that we were missing.Whether you're starting from scratch orfixing what you already have, AI becomesyour prompting partner. I use this allthe time for everything from personalstuff, business strategy, contentcreation, and even data analysis.Instead of trying to guess why I didn'tget the best result from a prompt, Ijust ask AI for feedback on the promptitself. But if you thought that havingAI write and improve your prompts wasnext level, then wait until you see whathappens when you stop using the same AImodel for everything. Hack number three.Here's what separates the AI beginnersfrom the pros. Your AI tool of choicehas different models that excel atdifferent things. And the model that youchoose can significantly impact thequality of your output and your results.The secret is understanding which modeldoes the task that you're asking it todo the best. Let me show you what I meanusing chat GBT as an example. So, if welook at ChatGpt, it has a bunch ofdifferent models. The 40 is great foreveryday tasks. The 4.5 excels at tasksrequiring a lot of emotionalintelligence, like creative writing, forexample. The 03 and the O4 Mini arebuilt for more deeper reasoning andcomplex problem solving. The 4.1 isgreat for analyzing information andgreat for business strategy. And the 4.1Mini is perfect for just quick,straightforward requests. Let me showyou. So, I'm going to give it a promptusing our six-part framework with theGPT 4.5 model for a creative writingtask. Here's the prompt I'm going togive it. You're a published novelistknown for emotionally resonant literaryfiction. A reader has just found an oldyellow tucked letter behind a loosefloorboard in their grandmother's attic,etc., etc., and write opening paragraphsthat capture the moments of thediscovery. Don't rush to reveal what theletter says, example tone, and it's verydescriptive kind of language. So, at theend of the prompt, we give it an exampleof what we're looking for in terms ofthe quality of the writing. All right,we're going to generate and see what itcomes up with. Wow, look at the result.You could see it's very descriptivelanguage and it really captured theexample that we gave it really well atthe end of our prompt, the example tone,and it really does sound like somethingyou'd read in a novel. Now, I'm going touse the exact same prompt with the 40model, which is more for kind ofeveryday uses, multiple different typesof uses, and see the comparison betweenthe two. Now, this one's pretty good,too, but when you look at the words it'susing, it's not nearly as descriptive ordramatic as what we got from the 4.5model. So the key takeaway here is thatthe model that you select can have asignificant impact on the result thatyou get. And the same principle appliesto whatever AI you're using, whetherit's Claude, Perplexity, Gemini, orother AI tools. They all have differentmodels optimized for different tasks.You wouldn't use a chef knife to flippancakes, right? Using the right modelfor the right job makes a hugedifference. Now, that hack was powerful,but if you don't combine it with whatI'm about to show you next, the way tomake AI its own editor, then you'remissing the real magic. Hack numberfour. This one's my favorite, andhonestly, it's like discovering that AIhas a hidden superpower. I accidentallydiscovered this when I got frustratedwith bad output. Instead of startingover, I asked AI to critique its ownwork. Let me show you this in action.I'm going to start with a LinkedIn postrequest using the framework that wetalked about. You are a career coachhelping professionals advance in theircareer. A mid-level professional intheir 30s wants to share insights aboutnetworking to build their personal brandon LinkedIn. Write a LinkedIn post aboutthe importance of networking for careergrowth. Return it as a 150word post withan engaging hook, a couple actionableinsights, questions to drive engagement,make it personal and authentic. Don'tuse corporate jargon or cliches and Igive it an example tone and we're goingto see what it comes up with. Okay,great. Here's the first draft. It'spretty good actually because we use theframework and it's structured, has theright tone, includes actionable advice.But watch what happens when I use theself-improvement loop. Now, I'm going tosay analyze your previous response andidentify three specific weaknesses. Thenrewrite it addressing those issues. Dothis three times, focusing on differentaspects each round. Look at this. It'sidentifying its own weaknesses. Thefirst draft, surface levelvulnerability, lack of emotional stakes,missed opportunities to reflect on theoutcome. And then here's version two.Much better, right? Looks better. Toneseems to be better. for improvedstorytelling and emotional engagement.But we're not done. Now, here's theoutput from round three. This one wasfocused on the call to action andengagement. The AI basically becomes itsown editor. Look at the progression. Wewent from good to great. Now, we have abunch of different versions that we canreview and decide which one we likebest. Or we can just ask AI whichversion is the best, like this. In thiscase, it liked round two overall becauseof the storytelling and therelatability, but it also liked round3's call to action. So, at the end ofthe output, it actually asks us if wewant to create a hybrid version thatcombines the strengths of the round twoand three versions, which I I think is agreat approach. So, instead of justaccepting the first version's output,you're forcing it to keep improving.It's like having a built-in qualitycontrol team that never gets tired. Now,what if I told you that there's foursimple words that can significantlyincrease the accuracy of any strategicor complex task. Hack number five is thefour-word miracle. Add these four wordsto any strategic or complex prompt.Think step by step. That's it. But don'tunderestimate it. I've tested this outon a lot of prompts and it consistentlygives you better, clearer, more reliableresults, especially for things likebusiness planning, marketing strategy,and content creation. Why? becauseyou're asking it to show its thoughtprocess instead of just jumping straightto the answer. Let me show you. Here's astrategic planning request. I want tocreate a content strategy for my fitnesscoaching business. I post on Instagramthree times per week. I have 5,000followers and I want to increaseengagement. My audience is busyprofessionals 28 to 40. Create a 30-daycontent plan. Now, when it generates theresponse, it gives me recommendations,but I don't see the thinking behind themor how everything connects together.Now, let me add those four magic words,think step by step, and we'll see whatit comes up with. Wow. See, look at thisbig difference. It's showing me thestrategic thinking step by step, theaudience analysis, content pillars,posting schedule, engagement tactics.Each piece builds on the last, and I canactually see the thinking behind everyrecommendation. Now, some of you mightbe wondering, well, why not use the 03model? Doesn't it show its workautomatically? And that's a greatquestion because yes, there are moreadvanced models like the O3 model thatdo often provide built-in reasoning. Buthere's the thing, not everyone hasaccess to those models. And for taskslike content strategy, like the examplethat we just went through, they're oftenoverkill based on my experience. So ifyou're using the free version ofChatubt, or you just want to keep thingssimple, this trick gives you alightweight workaround for better, morestrategic results. This can work forbusiness planning, calculations,decision-making, anything where you wantclearer thinking without the complexity.That four-word trick is incrediblypowerful for reliability, but this nexthack is my secret weapon for gettingstrategic answers you'd normally have topay a consultant for. Hack number six isthe priming trick. Instead of jumpingstraight to my specific question, I'mgoing to ask a broader question first toactivate all the AI's relevantknowledge. Let's say I was creating anonline Excel course for adults and Iwanted some help with the coursestructure and the program. First, I'mgoing to ask it this. What psychologicaland educational factors make onlinelearning most effective for adultlearners? And here's what it generates.Wow, look at this response. Verydetailed. Talks about the autonomy ofthe adults, self-direction, internalmotivations, practical applications,confidence building. Really goodinsights for us to then use for the nextprompt. So, now that we've primed AI'sknowledge and it has all of that greatinformation in its memory, we're goingto follow up with another prompt. Youare an instructional design expertspecializing in adult education. I'mcreating a 2-hour online course aboutExcel for small business owners who areintimidated by spreadsheets and havelimited time. Based on the learningprinciples you just outlined, providesome key strategies for my course,content delivery, and examples. Returnas a structured plan with five keyrecommendations. and focus on reducingoverwhelm and increasing confidence,etc., etc. And here's what it comes upwith. Really, really good information.So, it's taking information from theprevious output that we got from it,psychological factors and things likethat, and it's addressing those thingswithin this prompt, which is amazing.Start with a confidence building quickwin, organize content into bite-sizedstandalone mini lessons. Lots of thoseinsights that we got from the previousprompt are included in here. The AIbasically downloaded its knowledge ofthe adult learning psychology first andthen it applied it to my specificsituation. So this approach gives us waymore strategic thinking that considersthe psychological part of it rather thanjust quick tips. And this primingtechnique works for any complex topic,business strategy, technical problems,creative projects, you name it. So nowyou've got these powerful techniques,but here's the trap that catches 90% ofpeople. They get one good result andthey think they're done. Real promptengineering means testing promptsmultiple times, finding patterns in thefailures, iterating and refining untilit's bulletproof. I have a library of myown tested prompts that work everysingle time. It took time to build, butnow I can handle some of my most tedioustasks in seconds. Now, when I need towrite a piece of content or an email, Idon't cross my fingers and hope for thebest. I use a prompt I've testedmultiple times that I know deliversexactly what I need. And for reallyimportant decisions like strategicbusiness choices or anything that couldimpact my reputation, I'll even run thesame prompt across multiple AI tools andhave one of them critique which responseis the best. That's the differencebetween just celebrating single wins andactually starting to build systems. Sohere's what I want you to do right now.Pick one thing that you ask AI to doregularly. Could be emails, creatingcontent, analyzing data, whichever task.Build a prompt using the six-partframework that I showed you. Add in acouple of the hacks I showed you andthen test it a few times. Refine ituntil the output is actually somethingthat you'd use. Do this for just oneprompt and you'll understand why somepeople are getting incredible resultswhile others are struggling with AI andyou'll join that small group of peoplethat actually knows how to leveragethese tools properly. And trust me, onceyou experience the difference, you'llnever go back to basic prompting again.If you enjoyed this video, then pleaseshow me your support by hitting thethumbs up button. It really helps thechannel. And if you want to learn moreabout how you can use AI to level upyour business and your life, then clickthis next video.\"\"\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:43:32.468631Z","iopub.execute_input":"2025-09-12T10:43:32.469081Z","iopub.status.idle":"2025-09-12T10:43:32.480008Z","shell.execute_reply.started":"2025-09-12T10:43:32.469055Z","shell.execute_reply":"2025-09-12T10:43:32.479180Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# 1.2 Text Splitting","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n\nchunks = text_splitter.create_documents([combined_transcript])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:10:11.990577Z","iopub.execute_input":"2025-09-12T11:10:11.990887Z","iopub.status.idle":"2025-09-12T11:10:12.004038Z","shell.execute_reply.started":"2025-09-12T11:10:11.990864Z","shell.execute_reply":"2025-09-12T11:10:12.003184Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"print(len(chunks))\n\n# for chunk in chunks:\n#     print(chunk.page_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T12:00:07.563249Z","iopub.execute_input":"2025-09-12T12:00:07.563564Z","iopub.status.idle":"2025-09-12T12:00:07.568602Z","shell.execute_reply.started":"2025-09-12T12:00:07.563541Z","shell.execute_reply":"2025-09-12T12:00:07.567645Z"}},"outputs":[{"name":"stdout","text":"79\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"# 1.3 Embedding","metadata":{}},{"cell_type":"code","source":"api_key='your_api_key'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:45:02.030442Z","iopub.execute_input":"2025-09-12T10:45:02.030755Z","iopub.status.idle":"2025-09-12T10:45:02.035045Z","shell.execute_reply.started":"2025-09-12T10:45:02.030729Z","shell.execute_reply":"2025-09-12T10:45:02.034075Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"embeddings = OpenAIEmbeddings(api_key=api_key, model=\"text-embedding-3-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:46:25.422780Z","iopub.execute_input":"2025-09-12T10:46:25.423176Z","iopub.status.idle":"2025-09-12T10:46:29.055697Z","shell.execute_reply.started":"2025-09-12T10:46:25.423152Z","shell.execute_reply":"2025-09-12T10:46:29.054752Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# 1.4 Storage in Vector Store","metadata":{}},{"cell_type":"code","source":"vector_store = FAISS.from_documents(chunks, embeddings)\n\n#vector_store.index_to_docstore_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T12:00:20.023558Z","iopub.execute_input":"2025-09-12T12:00:20.023843Z","iopub.status.idle":"2025-09-12T12:00:21.799651Z","shell.execute_reply.started":"2025-09-12T12:00:20.023824Z","shell.execute_reply":"2025-09-12T12:00:21.798711Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"vector_store.get_by_ids(['9e1017d7-c188-44f8-a684-75a1aca081a4'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:48:29.730966Z","iopub.execute_input":"2025-09-12T10:48:29.731566Z","iopub.status.idle":"2025-09-12T10:48:29.737878Z","shell.execute_reply.started":"2025-09-12T10:48:29.731536Z","shell.execute_reply":"2025-09-12T10:48:29.736966Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[Document(id='9e1017d7-c188-44f8-a684-75a1aca081a4', metadata={}, page_content=\"hacks I showed you andthen test it a few times. Refine ituntil the output is actually somethingthat you'd use. Do this for just oneprompt and you'll understand why somepeople are getting incredible resultswhile others are struggling with AI andyou'll join that small group of peoplethat actually knows how to leveragethese tools properly. And trust me, onceyou experience the difference, you'llnever go back to basic prompting again.If you enjoyed this video, then pleaseshow me your support by\")]"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# 2. Retrievel","metadata":{}},{"cell_type":"code","source":"# using similarity search\n\nretriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:10:58.295196Z","iopub.execute_input":"2025-09-12T11:10:58.295479Z","iopub.status.idle":"2025-09-12T11:10:58.300362Z","shell.execute_reply.started":"2025-09-12T11:10:58.295458Z","shell.execute_reply":"2025-09-12T11:10:58.299472Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"#query = \"Summarise langchain in 50 words?\"\n#retriever.invoke(query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T12:00:34.013682Z","iopub.execute_input":"2025-09-12T12:00:34.013971Z","iopub.status.idle":"2025-09-12T12:00:34.018354Z","shell.execute_reply.started":"2025-09-12T12:00:34.013949Z","shell.execute_reply":"2025-09-12T12:00:34.017377Z"}},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"# 3. Augmentation","metadata":{}},{"cell_type":"code","source":"prompt = PromptTemplate(\n    template=\"\"\"You are a helpful assistant. Help finding the response to the query using the provided context only. If the query cannot be answered based on the context knowledge, respond back No answer in the context.\n        context: {context}\n        query: {query}\n    \"\"\",\n    input_variables=[\"context\", \"query\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:59:11.465748Z","iopub.execute_input":"2025-09-12T10:59:11.466060Z","iopub.status.idle":"2025-09-12T10:59:11.470491Z","shell.execute_reply.started":"2025-09-12T10:59:11.466036Z","shell.execute_reply":"2025-09-12T10:59:11.469594Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"query = \"Summarise langchain in 50 words?\"\nretreived_docs = retriever.invoke(query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T12:00:56.312534Z","iopub.execute_input":"2025-09-12T12:00:56.312805Z","iopub.status.idle":"2025-09-12T12:00:56.729013Z","shell.execute_reply.started":"2025-09-12T12:00:56.312788Z","shell.execute_reply":"2025-09-12T12:00:56.728147Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"context = '\\n\\n'.join(doc.page_content for doc in retreived_docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:15:52.696611Z","iopub.execute_input":"2025-09-12T11:15:52.696919Z","iopub.status.idle":"2025-09-12T11:15:52.701265Z","shell.execute_reply.started":"2025-09-12T11:15:52.696893Z","shell.execute_reply":"2025-09-12T11:15:52.700366Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"final_prompt = prompt.invoke({\"context\":context, \"query\": query})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:15:54.407686Z","iopub.execute_input":"2025-09-12T11:15:54.407968Z","iopub.status.idle":"2025-09-12T11:15:54.413111Z","shell.execute_reply.started":"2025-09-12T11:15:54.407941Z","shell.execute_reply":"2025-09-12T11:15:54.412423Z"}},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":"# 4. Generation","metadata":{}},{"cell_type":"code","source":"llm = ChatOpenAI(api_key=api_key, model=\"gpt-4o-mini\", temperature=0.5) # temperature - range of creativity 1- least creative, 0 - most creative","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:04:15.712077Z","iopub.execute_input":"2025-09-12T11:04:15.713008Z","iopub.status.idle":"2025-09-12T11:04:15.717543Z","shell.execute_reply.started":"2025-09-12T11:04:15.712977Z","shell.execute_reply":"2025-09-12T11:04:15.716687Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"final_response = llm.invoke(final_prompt)\n\nprint(final_response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:15:57.281201Z","iopub.execute_input":"2025-09-12T11:15:57.281522Z","iopub.status.idle":"2025-09-12T11:15:58.690065Z","shell.execute_reply.started":"2025-09-12T11:15:57.281496Z","shell.execute_reply":"2025-09-12T11:15:58.689324Z"}},"outputs":[{"name":"stdout","text":"No answer in the context.\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"# Combining the Chain","metadata":{}},{"cell_type":"code","source":"from langchain_core.runnables import RunnableParallel, RunnableSequence, RunnablePassthrough, RunnableLambda\nfrom langchain_core.output_parsers import StrOutputParser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:26:44.441929Z","iopub.execute_input":"2025-09-12T11:26:44.442365Z","iopub.status.idle":"2025-09-12T11:26:44.446677Z","shell.execute_reply.started":"2025-09-12T11:26:44.442327Z","shell.execute_reply":"2025-09-12T11:26:44.445759Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def create_context(retreived_docs):\n    context = '\\n\\n'.join(doc.page_content for doc in retreived_docs)\n    return context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:21:20.503110Z","iopub.execute_input":"2025-09-12T11:21:20.503467Z","iopub.status.idle":"2025-09-12T11:21:20.508141Z","shell.execute_reply.started":"2025-09-12T11:21:20.503442Z","shell.execute_reply":"2025-09-12T11:21:20.507156Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"parallel_chain = RunnableParallel({\n    \"context\": retriever | RunnableLambda(create_context),\n    \"query\": RunnablePassthrough()\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:28:21.796543Z","iopub.execute_input":"2025-09-12T11:28:21.796835Z","iopub.status.idle":"2025-09-12T11:28:21.801337Z","shell.execute_reply.started":"2025-09-12T11:28:21.796818Z","shell.execute_reply":"2025-09-12T11:28:21.800493Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"query = \"Summarise langchain in 50 words?\"\n\n#parallel_chain.invoke(query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T12:01:33.114779Z","iopub.execute_input":"2025-09-12T12:01:33.115108Z","iopub.status.idle":"2025-09-12T12:01:33.119307Z","shell.execute_reply.started":"2025-09-12T12:01:33.115084Z","shell.execute_reply":"2025-09-12T12:01:33.118547Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"str_parser = StrOutputParser()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:27:03.562268Z","iopub.execute_input":"2025-09-12T11:27:03.563069Z","iopub.status.idle":"2025-09-12T11:27:03.566575Z","shell.execute_reply.started":"2025-09-12T11:27:03.563041Z","shell.execute_reply":"2025-09-12T11:27:03.565819Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"main_chain = parallel_chain | prompt | llm | str_parser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:28:31.405042Z","iopub.execute_input":"2025-09-12T11:28:31.405411Z","iopub.status.idle":"2025-09-12T11:28:31.410515Z","shell.execute_reply.started":"2025-09-12T11:28:31.405386Z","shell.execute_reply":"2025-09-12T11:28:31.409678Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"result = main_chain.invoke(query)\n\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:28:33.095191Z","iopub.execute_input":"2025-09-12T11:28:33.095478Z","iopub.status.idle":"2025-09-12T11:28:34.753156Z","shell.execute_reply.started":"2025-09-12T11:28:33.095458Z","shell.execute_reply":"2025-09-12T11:28:34.752213Z"}},"outputs":[{"name":"stdout","text":"LangChain is a powerful library for building LLM-powered applications. It simplifies the integration of various components, enabling natural language understanding and efficient query handling. Users can interact with documents, generate summaries, and create practice questions, making it an invaluable tool for developers in machine learning and AI applications.\n","output_type":"stream"}],"execution_count":74},{"cell_type":"markdown","source":"","metadata":{}}]}